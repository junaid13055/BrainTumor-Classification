{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "jYFgzP1rsgw7",
        "outputId": "5ec8754f-dcc3-41d5-aae8-21fb6d1d5863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 20] Not a directory: '/content/drive/MyDrive/BTC/BTC_Dataset-20241127T202613Z-001.zip/BTC_Dataset/'\n",
            "/content/drive/MyDrive/BTC/BTC_Dataset\n"
          ]
        }
      ],
      "source": [
        "# Importing required libraries for image preprocessing, model training, and evaluation\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers, models\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounting Google Drive to access dataset\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/BTC/BTC_Dataset/\n",
        "# Function to crop image and focus on the Region of Interest (ROI) around the tumor\n",
        "def crop_to_roi(image, margin=20):\n",
        "    img_copy = image.copy()\n",
        "\n",
        "    try:\n",
        "        height, width, channels = img_copy.shape\n",
        "    except:\n",
        "        height, width = img_copy.shape\n",
        "\n",
        "    # Convert to grayscale and apply binary thresholding\n",
        "    gray_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "    _, threshold_img = cv2.threshold(gray_img, 20, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Find contours and pick the largest one (tumor)\n",
        "    contours, _ = cv2.findContours(threshold_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    # Get the bounding box of the largest contour\n",
        "    left = min(largest_contour, key=lambda x: x[0][0])[0][0] - margin\n",
        "    top = min(largest_contour, key=lambda x: x[0][1])[0][1] - margin\n",
        "    right = max(largest_contour, key=lambda x: x[0][0])[0][0] + margin\n",
        "    bottom = max(largest_contour, key=lambda x: x[0][1])[0][1] + margin\n",
        "\n",
        "    # Ensure bounding box stays within image dimensions\n",
        "    left = max(0, left)\n",
        "    top = max(0, top)\n",
        "    right = min(width, right)\n",
        "    bottom = min(height, bottom)\n",
        "\n",
        "    # Crop and return the image\n",
        "    return image[top:bottom, left:right]\n",
        "\n",
        "# Function to load and preprocess images from the dataset\n",
        "def load_and_process_images(dataset_path, target_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    filenames = []\n",
        "\n",
        "    # Traverse dataset directory and process each image\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        for img_file in os.listdir(f\"{dataset_path}/{class_folder}\"):\n",
        "            img_path = f\"{dataset_path}/{class_folder}/{img_file}\"\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Crop and resize the image\n",
        "            img = crop_to_roi(img, margin=5)\n",
        "            img = cv2.resize(img, target_size)\n",
        "\n",
        "            # Augment by flipping images horizontally and vertically\n",
        "            images.append(img)\n",
        "            labels.append(class_folder)\n",
        "            filenames.append(img_file)\n",
        "\n",
        "            # Horizontal flip\n",
        "            images.append(cv2.flip(img, 1))\n",
        "            labels.append(class_folder)\n",
        "            filenames.append(img_file)\n",
        "\n",
        "            # Vertical flip\n",
        "            images.append(cv2.flip(img, 0))\n",
        "            labels.append(class_folder)\n",
        "            filenames.append(img_file)\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(filenames)\n",
        "\n",
        "# Define paths\n",
        "TRAIN_PATH = \"Training\"\n",
        "VAL_PATH = \"Validation\"\n",
        "TEST_PATH = \"Testing\"\n",
        "\n",
        "# Get list of classes from the training set\n",
        "class_names = [folder for folder in os.listdir(TRAIN_PATH)]\n",
        "\n",
        "# Define image target size\n",
        "image_size = (128, 128, 3)\n",
        "\n",
        "# Load and preprocess images for training, validation, and testing\n",
        "train_images, train_labels, _ = load_and_process_images(TRAIN_PATH, image_size[:2])\n",
        "val_images, val_labels, _ = load_and_process_images(VAL_PATH, image_size[:2])\n",
        "test_images, test_labels, _ = load_and_process_images(TEST_PATH, image_size[:2])\n",
        "\n",
        "# Display sample images (optional)\n",
        "def display_image(image):\n",
        "    cv2.imshow('Image', image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "display_image(train_images[0])\n",
        "display_image(val_images[0])\n",
        "display_image(test_images[0])\n",
        "\n",
        "# Convert string labels to categorical (one-hot encoding)\n",
        "train_labels_cat = tf.keras.utils.to_categorical([class_names.index(label) for label in train_labels])\n",
        "val_labels_cat = tf.keras.utils.to_categorical([class_names.index(label) for label in val_labels])\n",
        "test_labels_cat = tf.keras.utils.to_categorical([class_names.index(label) for label in test_labels])\n",
        "\n",
        "# Build the model using EfficientNetB4\n",
        "def build_model(base_model_name='EfficientNetB4'):\n",
        "    base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights=\"imagenet\", input_shape=image_size, pooling='max')\n",
        "\n",
        "    # Add custom layers on top\n",
        "    x = base_model.output\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.02),\n",
        "                     activity_regularizer=regularizers.l1(0.006))(x)\n",
        "    x = layers.Dropout(0.45)(x)\n",
        "    output = layers.Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "model = build_model()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels_cat, epochs=10, validation_data=(val_images, val_labels_cat))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels_cat, verbose=2)\n",
        "\n",
        "# Generate predictions on the test set\n",
        "test_preds = model.predict(test_images)\n",
        "test_preds = np.argmax(test_preds, axis=1)\n",
        "test_labels_max = np.argmax(test_labels_cat, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_labels_max, test_preds))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(test_labels_max, test_preds)\n",
        "print(\"Confusion Matrix: \\n\", cm)\n",
        "print(\"Per-class accuracy: \\n\", cm.diagonal() / cm.sum(axis=1))\n",
        "\n",
        "# Plot accuracy and loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy & Loss')\n",
        "plt.legend(loc='upper center', bbox_to_anchor=(1.1, 0.5), ncol=2, fancybox=True, shadow=True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4DOfEDfubbP"
      },
      "outputs": [],
      "source": [
        "# Function to load and preprocess images\n",
        "def load_images(path, image_size):\n",
        "    images, labels, names = [], [], []\n",
        "    for sub_dir in os.listdir(path):\n",
        "        sub_path = os.path.join(path, sub_dir)\n",
        "        if not os.path.isdir(sub_path):\n",
        "            continue\n",
        "\n",
        "        # Check if subdirectory contains images\n",
        "        if not os.listdir(sub_path):\n",
        "            print(f\"Warning: Directory '{sub_path}' is empty.\")\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(sub_path):\n",
        "            img_path = os.path.join(sub_path, img_name)\n",
        "            img = cv.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"Warning: Could not read image '{img_path}'. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            img = crop_image(img, GAP_VAL=5)\n",
        "            img = cv.resize(img, image_size)\n",
        "\n",
        "            # Add original and augmented images\n",
        "            for aug_img in [img, cv.flip(img, 1), cv.flip(img, 0)]:\n",
        "                images.append(aug_img)\n",
        "                labels.append(sub_dir)\n",
        "                names.append(img_name)\n",
        "\n",
        "    # Check if any images were loaded\n",
        "    if not images:\n",
        "        raise ValueError(f\"No images found in directory '{path}'.\")\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(names)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}