{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edE6JedKinX7",
        "outputId": "9de9930a-b0f6-481a-8c3c-ebbd3e906455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/BTC_Dataset\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers, models\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Mounting Google Drive to access dataset\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/BTC_Dataset/\n",
        "\n",
        "\n",
        "# Function to crop image and focus on the Region of Interest (ROI) around the tumor\n",
        "def crop_to_roi(image, margin=20):\n",
        "    img_copy = image.copy()\n",
        "    try:\n",
        "        height, width, channels = img_copy.shape\n",
        "    except:\n",
        "        height, width = img_copy.shape\n",
        "\n",
        "\n",
        "    # Convert to grayscale and apply binary thresholding\n",
        "    gray_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "    _, threshold_img = cv2.threshold(gray_img, 20, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "\n",
        "    # Find contours and pick the largest one (tumor)\n",
        "    contours, _ = cv2.findContours(threshold_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "\n",
        "    # Get the bounding box of the largest contour\n",
        "    left = min(largest_contour, key=lambda x: x[0][0])[0][0] - margin\n",
        "    top = min(largest_contour, key=lambda x: x[0][1])[0][1] - margin\n",
        "    right = max(largest_contour, key=lambda x: x[0][0])[0][0] + margin\n",
        "    bottom = max(largest_contour, key=lambda x: x[0][1])[0][1] + margin\n",
        "\n",
        "\n",
        "    # Ensure bounding box stays within image dimensions\n",
        "    left = max(0, left)\n",
        "    top = max(0, top)\n",
        "    right = min(width, right)\n",
        "    bottom = min(height, bottom)\n",
        "\n",
        "\n",
        "    # Crop and return the image\n",
        "    return image[top:bottom, left:right]\n",
        "\n",
        "\n",
        "# Function to load and preprocess images from the dataset\n",
        "def load_and_process_images(dataset_path, target_size):\n",
        "    images = []\n",
        "    labels = []\n",
        "    filenames = []\n",
        "\n",
        "\n",
        "    # Traverse dataset directory and process each image\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        for img_file in os.listdir(f\"{dataset_path}/{class_folder}\"):\n",
        "            img_path = f\"{dataset_path}/{class_folder}/{img_file}\"\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "\n",
        "            # Crop and resize the image\n",
        "            img = crop_to_roi(img, margin=5)\n",
        "            img = cv2.resize(img, target_size)\n",
        "\n",
        "\n",
        "            # Augment by flipping images horizontally and vertically\n",
        "            images.append(img)\n",
        "            labels.append(class_folder)\n",
        "            filenames.append(img_file)\n",
        "\n",
        "\n",
        "            # Horizontal flip\n",
        "            images.append(cv2.flip(img, 1))\n",
        "            labels.append(class_folder)\n",
        "            filenames.append(img_file)\n",
        "\n",
        "\n",
        "            # Vertical flip\n",
        "            images.append(cv2.flip(img, 0))\n",
        "            labels.append(class_folder)\n",
        "            filenames.append(img_file)\n",
        "\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(filenames)\n",
        "\n",
        "\n",
        "# Define paths\n",
        "TRAIN_PATH = \"Training\"\n",
        "VAL_PATH = \"Validation\"\n",
        "TEST_PATH = \"Testing\"\n",
        "\n",
        "\n",
        "# Get list of classes from the training set\n",
        "class_names = [folder for folder in os.listdir(TRAIN_PATH)]\n",
        "\n",
        "\n",
        "# Define image target size\n",
        "image_size = (128, 128, 3)\n",
        "\n",
        "\n",
        "# Load and preprocess images for training, validation, and testing\n",
        "train_images, train_labels, _ = load_and_process_images(TRAIN_PATH, image_size[:2])\n",
        "val_images, val_labels, _ = load_and_process_images(VAL_PATH, image_size[:2])\n",
        "test_images, test_labels, _ = load_and_process_images(TEST_PATH, image_size[:2])\n",
        "\n",
        "\n",
        "# Convert string labels to categorical (one-hot encoding)\n",
        "train_labels_cat = tf.keras.utils.to_categorical([class_names.index(label) for label in train_labels])\n",
        "val_labels_cat = tf.keras.utils.to_categorical([class_names.index(label) for label in val_labels])\n",
        "test_labels_cat = tf.keras.utils.to_categorical([class_names.index(label) for label in test_labels])\n",
        "\n",
        "\n",
        "\n",
        "# Training and evaluation for EfficientNetB4\n",
        "def train_efficientnet():\n",
        "    efficient_net = tf.keras.applications.EfficientNetB4(include_top=False, weights=\"imagenet\", input_shape=image_size, pooling=None)\n",
        "    x = layers.GlobalAveragePooling2D()(efficient_net.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.02),\n",
        "                     activity_regularizer=regularizers.l1(0.006))(x)\n",
        "    x = layers.Dropout(0.45)(x)\n",
        "    output = layers.Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "\n",
        "    model = models.Model(inputs=efficient_net.input, outputs=output)\n",
        "    model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "    history = model.fit(train_images, train_labels_cat, epochs=10, validation_data=(val_images, val_labels_cat))\n",
        "\n",
        "\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels_cat)\n",
        "    print(f\"EfficientNetB4 Test Accuracy: {test_acc}\")\n",
        "    print(f\"EfficientNetB4 Test Loss: {test_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "    test_predictions = np.argmax(model.predict(test_images), axis=1)\n",
        "    test_labels_class = np.argmax(test_labels_cat, axis=1)\n",
        "\n",
        "\n",
        "    print(\"EfficientNetB4 Confusion Matrix:\")\n",
        "    cm = confusion_matrix(test_labels_class, test_predictions)\n",
        "    print(cm)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(\"EfficientNetB4 Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print(\"EfficientNetB4 Classification Report:\")\n",
        "    print(classification_report(test_labels_class, test_predictions, target_names=class_names))\n",
        "\n",
        "\n",
        "    plt.plot(history.history['accuracy'], label='train accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
        "    plt.title('EfficientNetB4 Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    train_efficientnet()\n"
      ]
    }
  ]
}